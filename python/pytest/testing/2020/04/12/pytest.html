<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Testing with pytest | Gunnhild’s notes</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Testing with pytest" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="pytest is a widely used Python framework for testing, which is flexible for small and large test suites." />
<meta property="og:description" content="pytest is a widely used Python framework for testing, which is flexible for small and large test suites." />
<link rel="canonical" href="https://gunnhildsp.github.io/notes/python/pytest/testing/2020/04/12/pytest.html" />
<meta property="og:url" content="https://gunnhildsp.github.io/notes/python/pytest/testing/2020/04/12/pytest.html" />
<meta property="og:site_name" content="Gunnhild’s notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-12T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"pytest is a widely used Python framework for testing, which is flexible for small and large test suites.","mainEntityOfPage":{"@type":"WebPage","@id":"https://gunnhildsp.github.io/notes/python/pytest/testing/2020/04/12/pytest.html"},"@type":"BlogPosting","headline":"Testing with pytest","dateModified":"2020-04-12T00:00:00-05:00","url":"https://gunnhildsp.github.io/notes/python/pytest/testing/2020/04/12/pytest.html","datePublished":"2020-04-12T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/notes/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://gunnhildsp.github.io/notes/feed.xml" title="Gunnhild's notes" /><link rel="shortcut icon" type="image/x-icon" href="/notes/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Testing with pytest | Gunnhild’s notes</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Testing with pytest" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="pytest is a widely used Python framework for testing, which is flexible for small and large test suites." />
<meta property="og:description" content="pytest is a widely used Python framework for testing, which is flexible for small and large test suites." />
<link rel="canonical" href="https://gunnhildsp.github.io/notes/python/pytest/testing/2020/04/12/pytest.html" />
<meta property="og:url" content="https://gunnhildsp.github.io/notes/python/pytest/testing/2020/04/12/pytest.html" />
<meta property="og:site_name" content="Gunnhild’s notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-04-12T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"pytest is a widely used Python framework for testing, which is flexible for small and large test suites.","mainEntityOfPage":{"@type":"WebPage","@id":"https://gunnhildsp.github.io/notes/python/pytest/testing/2020/04/12/pytest.html"},"@type":"BlogPosting","headline":"Testing with pytest","dateModified":"2020-04-12T00:00:00-05:00","url":"https://gunnhildsp.github.io/notes/python/pytest/testing/2020/04/12/pytest.html","datePublished":"2020-04-12T00:00:00-05:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://gunnhildsp.github.io/notes/feed.xml" title="Gunnhild's notes" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head><body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/notes/">Gunnhild&#39;s notes</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/notes/about/">About</a><a class="page-link" href="/notes/search/">Search</a><a class="page-link" href="/notes/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Testing with pytest</h1><p class="page-description">pytest is a widely used Python framework for testing, which is flexible for small and large test suites.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-04-12T00:00:00-05:00" itemprop="datePublished">
        Apr 12, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      18 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/notes/categories/#python">python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/notes/categories/#pytest">pytest</a>
        &nbsp;
      
        <a class="category-tags-link" href="/notes/categories/#testing">testing</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/gunnhildsp/notes/tree/master/_notebooks/2020-04-12-pytest.ipynb" role="button">
<img class="notebook-badge-image" src="/notes/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div><div class="px-2">
    <a href="https://colab.research.google.com/github/gunnhildsp/notes/blob/master/_notebooks/2020-04-12-pytest.ipynb">
        <img class="notebook-badge-image" src="/notes/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#You-should-test-your-code">You should test your code </a></li>
<li class="toc-entry toc-h2"><a href="#Put-your-tests-where-pytest-can-find-them">Put your tests where pytest can find them </a></li>
<li class="toc-entry toc-h2"><a href="#Run-your-tests">Run your tests </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Run-all-tests">Run all tests </a></li>
<li class="toc-entry toc-h3"><a href="#Customize-test-output">Customize test output </a></li>
<li class="toc-entry toc-h3"><a href="#Specify-modules,-files-or-single-tests">Specify modules, files or single tests </a></li>
<li class="toc-entry toc-h3"><a href="#Group-tests-using-marks">Group tests using marks </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Use-fixtures-to-initialize-your-test">Use fixtures to initialize your test </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Create-test-data-in-fixtures">Create test data in fixtures </a></li>
<li class="toc-entry toc-h3"><a href="#Use-monkeypatch-to-set-environment-variables">Use monkeypatch to set environment variables </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Use-mocks-to-test-external-dependencies">Use mocks to test external dependencies </a></li>
<li class="toc-entry toc-h2"><a href="#Use-parametrization-to-cover-multiple-cases">Use parametrization to cover multiple cases </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Parametrizing-fixtures-to-cover-multiple-test-cases">Parametrizing fixtures to cover multiple test cases </a></li>
<li class="toc-entry toc-h3"><a href="#Parametrize-tests-to-cover-multiple-test-cases">Parametrize tests to cover multiple test cases </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Testing-that-exceptions-are-raised">Testing that exceptions are raised </a></li>
<li class="toc-entry toc-h2"><a href="#Further-reading">Further reading </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-04-12-pytest.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="You-should-test-your-code">
<a class="anchor" href="#You-should-test-your-code" aria-hidden="true"><span class="octicon octicon-link"></span></a>You should test your code<a class="anchor-link" href="#You-should-test-your-code"> </a>
</h2>
<p>There are many reasons why you should test your code:</p>
<ul>
<li>Writing a test helps you define what your code should do and helps you enforce single responsibility of functions. </li>
<li>Getting into a habit of writing tests for corner cases helps you develop more robust code.</li>
<li>If your tests have good names and reasonable test cases it serves as documentation of your code for your future self or other collaborators. </li>
<li>It is a good way of documenting assumptions you make. It is often useful to write a test that fails in the event of an assumption being broken, such as functionality you have not implemented yet. </li>
<li>Many IDEs have good built-in support for running tests, and debugging a test is often my main way of either debugging through my own code to find errors, or stepping through code that is unfamiliar to me to se how the code is supposed to work and fail. </li>
<li>Good test coverage is essential when refactoring code.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Put-your-tests-where-pytest-can-find-them">
<a class="anchor" href="#Put-your-tests-where-pytest-can-find-them" aria-hidden="true"><span class="octicon octicon-link"></span></a>Put your tests where pytest can find them<a class="anchor-link" href="#Put-your-tests-where-pytest-can-find-them"> </a>
</h2>
<p><a href="https://docs.pytest.org/en/latest/">pytest</a> finds your tests automatically according to (what I have just learned is) <a href="https://docs.pytest.org/en/latest/goodpractices.html#conventions-for-python-test-discovery">standard test discovery</a> by:</p>
<ul>
<li>recursively looking through directories</li>
<li>search for files named <code>test_*.py</code> or <code>*_test.py</code>
</li>
<li>in those files: search for functions prefixed with <a href="/notes/images/copied_from_nb/test"><code>test</code></a> outside classes</li>
<li>in those files: search for functions or methods inside classes prefixed with <code>Test</code>
</li>
</ul>
<p>An example of a directory structure could look like this:</p>

<pre><code>my_code/
    app.py
    utils.py
tests/
    test_app.py
    test_utils.py</code></pre>
<p>It is good practice to organize your tests separately from the rest of your code, for example in a folder named <code>tests</code> as above. There are <a href="https://blog.ionelmc.ro/2014/05/25/python-packaging/#the-structure">many reasons</a>, for example default module discovery may ignore your tests, your tests may require additional packages to run, and if you are writing a library or application, the tests should not need to be included in your library or application.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Run-your-tests">
<a class="anchor" href="#Run-your-tests" aria-hidden="true"><span class="octicon octicon-link"></span></a>Run your tests<a class="anchor-link" href="#Run-your-tests"> </a>
</h2>
<p>I normally use PyCharm and find the built-in functionality for running and debugging tests from the interface quite nice, but it is always cool to learn more CLI tricks.</p>
<h3 id="Run-all-tests">
<a class="anchor" href="#Run-all-tests" aria-hidden="true"><span class="octicon octicon-link"></span></a>Run all tests<a class="anchor-link" href="#Run-all-tests"> </a>
</h3>
<p>Running all tests found from the current directory is quite simple:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python -m pytest
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-bold">============================= test session starts ==============================</span>
platform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1
rootdir: /Users/Gunnhild/code/notes/_notebooks, inifile: pytest.ini
collected 6 items                                                              <span class="ansi-bold">

test_examples.py </span><span class="ansi-green-intense-fg ansi-bold">.</span><span class="ansi-red-fg">F</span><span class="ansi-red-fg">                                                      [ 33%]</span>
test_fixturefunctions.py <span class="ansi-green-fg">.</span><span class="ansi-red-fg">                                               [ 50%]</span>
test_mark_examples.py <span class="ansi-green-fg">.</span><span class="ansi-green-fg">.</span><span class="ansi-green-fg">.</span><span class="ansi-red-fg">                                                [100%]</span>

=================================== FAILURES ===================================
<span class="ansi-red-intense-fg ansi-bold">_____________________________ test_failing_example _____________________________</span>

    <span class="ansi-blue-intense-fg">def</span> <span class="ansi-green-intense-fg">test_failing_example</span>():
        <span class="ansi-cyan-intense-fg">print</span>(<span class="ansi-yellow-fg">"</span><span class="ansi-yellow-fg">Hello</span><span class="ansi-yellow-fg">"</span>)
&gt;       <span class="ansi-blue-intense-fg">assert</span> <span class="ansi-blue-intense-fg">False</span>
<span class="ansi-red-intense-fg ansi-bold">E       assert False</span>

<span class="ansi-red-intense-fg ansi-bold">test_examples.py</span>:9: AssertionError
----------------------------- Captured stdout call -----------------------------
Hello
=========================== short test summary info ============================
FAILED test_examples.py::test_failing_example - assert False
<span class="ansi-red-fg">========================= </span><span class="ansi-red-intense-fg ansi-bold">1 failed</span>, <span class="ansi-green-fg">5 passed</span><span class="ansi-red-fg"> in 0.83s</span><span class="ansi-red-fg"> ==========================</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Note:</strong> We can run the tests by running either <code>python -m pytest</code> or just <code>pytest</code>. Running through python will add the current directory to <code>sys.path</code> which is often desirable, therefore I'll stick with that.</p>
<p>Here, <code>pytest</code> discovered three file with tests, <code>test_examples.py</code>, containing two tests, one which passes and one which fails, <code>test_fixturefunctions.py</code>, containing one passing test and <code>test_mark_examples.py</code>, containing three passing tests. The tests in <code>test_examples.py</code> look like this:</p>
<div class="highlight"><pre><span></span><span class="c1"># contents of test_examples.py</span>
<span class="k">def</span> <span class="nf">test_example</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Hi"</span><span class="p">)</span>
    <span class="k">assert</span> <span class="kc">True</span>

<span class="k">def</span> <span class="nf">test_failing_example</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Hello"</span><span class="p">)</span>
    <span class="k">assert</span> <span class="kc">False</span>
</pre></div>
<h3 id="Customize-test-output">
<a class="anchor" href="#Customize-test-output" aria-hidden="true"><span class="octicon octicon-link"></span></a>Customize test output<a class="anchor-link" href="#Customize-test-output"> </a>
</h3>
<p>The default mode is that output from a test is not shown unless the test fails. We can use the <code>capture</code> option to <strong>print output</strong> anyway, or <code>-s</code> for short:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python -m pytest test_examples.py::test_example --capture<span class="o">=</span>no
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-bold">============================= test session starts ==============================</span>
platform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1
rootdir: /Users/Gunnhild/code/notes/_notebooks, inifile: pytest.ini
collected 1 item                                                               

test_examples.py Hi
<span class="ansi-green-fg">.</span>

<span class="ansi-green-fg">============================== </span><span class="ansi-green-intense-fg ansi-bold">1 passed</span><span class="ansi-green-fg"> in 0.01s</span><span class="ansi-green-fg"> ===============================</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The traceback formatting for failing tests is set by the option <code>tb</code>. There are many <a href="https://docs.pytest.org/en/latest/usage.html#modifying-python-traceback-printing">options</a>, such as <code>--tb=line</code> to limit output from failing tests to one line:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python -m pytest test_examples.py --tb<span class="o">=</span>line
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-bold">============================= test session starts ==============================</span>
platform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1
rootdir: /Users/Gunnhild/code/notes/_notebooks, inifile: pytest.ini
collected 2 items                                                              

test_examples.py <span class="ansi-green-fg">.</span><span class="ansi-red-fg">F</span><span class="ansi-red-fg">                                                      [100%]</span>

=================================== FAILURES ===================================
/Users/Gunnhild/code/notes/_notebooks/test_examples.py:9: assert False
=========================== short test summary info ============================
FAILED test_examples.py::test_failing_example - assert False
<span class="ansi-red-fg">========================= </span><span class="ansi-red-intense-fg ansi-bold">1 failed</span>, <span class="ansi-green-fg">1 passed</span><span class="ansi-red-fg"> in 0.06s</span><span class="ansi-red-fg"> ==========================</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Specify-modules,-files-or-single-tests">
<a class="anchor" href="#Specify-modules,-files-or-single-tests" aria-hidden="true"><span class="octicon octicon-link"></span></a>Specify modules, files or single tests<a class="anchor-link" href="#Specify-modules,-files-or-single-tests"> </a>
</h3>
<p>Above we used a trick: We can <strong>run tests found in a single file and a single test</strong> from the command line as well, using the syntax</p>

<pre><code>pytest test_module/test_file_name.py::test_function_name</code></pre>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python -m pytest test_examples.py::test_example
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-bold">============================= test session starts ==============================</span>
platform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1
rootdir: /Users/Gunnhild/code/notes/_notebooks
collected 1 item                                                               

test_examples.py <span class="ansi-green-fg">.</span><span class="ansi-green-fg">                                                       [100%]</span>

<span class="ansi-green-fg">============================== </span><span class="ansi-green-intense-fg ansi-bold">1 passed</span><span class="ansi-green-fg"> in 0.01s</span><span class="ansi-green-fg"> ===============================</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Group-tests-using-marks">
<a class="anchor" href="#Group-tests-using-marks" aria-hidden="true"><span class="octicon octicon-link"></span></a>Group tests using marks<a class="anchor-link" href="#Group-tests-using-marks"> </a>
</h3>
<p>We can use <a href="https://docs.pytest.org/en/latest/mark.html">marks</a> to run groups of tests easily with the <code>-m</code> option</p>

<pre><code>python -m pytest -m mark_name</code></pre>
<p><code>pytest</code> has a range of built-in marks, such as the <code>slow</code> mark. This can be used to group tests so that you can run the quick tests and check for failures there first, before running the slow tests. We register our marks in <code>pytest.ini</code> to let pytest know we are marking on purpose, otherwise pytest will raise a Warning. 
For example, we could mark tests for different purposes:</p>
<div class="highlight"><pre><span></span><span class="c1"># contents of test_examples.py</span>
<span class="kn">import</span> <span class="nn">pytest</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">this</span>
<span class="k">def</span> <span class="nf">test_example</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Hello"</span><span class="p">)</span>
    <span class="k">assert</span> <span class="kc">True</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">this</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">that</span>
<span class="k">def</span> <span class="nf">test_several_marks</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Nothing"</span><span class="p">)</span>
    <span class="k">assert</span> <span class="kc">True</span>

<span class="k">def</span> <span class="nf">test_unmarked</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Hello"</span><span class="p">)</span>
    <span class="k">assert</span> <span class="mi">1</span>
</pre></div>
<p>Our pytest.ini should then look like</p>

<pre><code># content of pytest.ini
[pytest]
markers =
    this: example of marker.
    that: another example of marker.</code></pre>
<p>and then we can run groups accordingly:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python -m pytest -m this
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-bold">============================= test session starts ==============================</span>
platform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1
rootdir: /Users/Gunnhild/code/notes/_notebooks, inifile: pytest.ini
collected 6 items / 4 deselected / 2 selected                                  <span class="ansi-bold">

test_mark_examples.py </span><span class="ansi-green-intense-fg ansi-bold">.</span><span class="ansi-green-fg">.</span><span class="ansi-green-fg">                                                 [100%]</span>

<span class="ansi-green-fg">======================= </span><span class="ansi-green-intense-fg ansi-bold">2 passed</span>, <span class="ansi-yellow-fg">4 deselected</span><span class="ansi-green-fg"> in 0.75s</span><span class="ansi-green-fg"> ========================</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python -m pytest -m <span class="s2">"this and not that"</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-bold">============================= test session starts ==============================</span>
platform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1
rootdir: /Users/Gunnhild/code/notes/_notebooks, inifile: pytest.ini
collected 6 items / 5 deselected / 1 selected                                  <span class="ansi-bold">

test_mark_examples.py </span><span class="ansi-green-intense-fg ansi-bold">.</span><span class="ansi-green-fg">                                                  [100%]</span>

<span class="ansi-green-fg">======================= </span><span class="ansi-green-intense-fg ansi-bold">1 passed</span>, <span class="ansi-yellow-fg">5 deselected</span><span class="ansi-green-fg"> in 0.59s</span><span class="ansi-green-fg"> ========================</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Use-fixtures-to-initialize-your-test">
<a class="anchor" href="#Use-fixtures-to-initialize-your-test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Use fixtures to initialize your test<a class="anchor-link" href="#Use-fixtures-to-initialize-your-test"> </a>
</h2>
<p>In software testing, a <a href="https://docs.pytest.org/en/latest/fixture.html">fixture</a> can be used to ensuring that tests are repeatable: the same code with the same inputs in the same environment will reproduce the same results. We can use fixtures for</p>
<ul>
<li>setting up mocks of external services such as APIs, so your tests won't depend on the reliability of external applications, and your can test all response cases you need to</li>
<li>setting up and sharing test data between tests</li>
<li>setting up the environment that the test will run in</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this example, we have a function that saves an input dataframe to a specified path as a csv file.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span> 


<span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">save_path</span><span class="p">:</span> <span class="n">Path</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">df</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
        <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Nothing to save. "</span><span class="p">)</span>
</pre></div>
<p>To test this function, we might want to save a dataframe, and check that we get the same result back when we read the csv file. For this test we use the built-in fixture <code>tmp_path</code>. The <code>tmp_path</code> fixture creates a path unique to each test run, that doesn't clutter the repository or any other shared folders we might care about. This ensures that if the tests are run in a different environment, such as on another developer's computer or in a continuous integration pipeline, the folders will exist when needed and be deleted eventually. We use any fixture in a test by using the fixture name as an input argument to the test function:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">pandas.testing</span> <span class="kn">import</span> <span class="n">assert_frame_equal</span>


<span class="k">def</span> <span class="nf">test_save</span><span class="p">(</span><span class="n">tmp_path</span><span class="p">):</span>
    <span class="c1"># Given</span>
    <span class="n">save_path</span> <span class="o">=</span> <span class="n">tmp_path</span> <span class="o">/</span> <span class="s2">"df.csv"</span>
    <span class="n">df_expected</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"a"</span><span class="p">,</span> <span class="s2">"b"</span><span class="p">,</span> <span class="s2">"c"</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">]))</span>
    <span class="n">save</span><span class="p">(</span><span class="n">df_expected</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>

    <span class="c1"># When </span>
    <span class="n">df_actual</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Then </span>
    <span class="n">assert_frame_equal</span><span class="p">(</span><span class="n">df_expected</span><span class="p">,</span> <span class="n">df_actual</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python -m pytest test_save_example.py::test_save
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-bold">============================= test session starts ==============================</span>
platform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1
rootdir: /Users/Gunnhild/code/notes/_notebooks, inifile: pytest.ini
collected 1 item                                                               <span class="ansi-bold">

test_save_example.py </span><span class="ansi-green-intense-fg ansi-bold">.</span><span class="ansi-green-fg">                                                   [100%]</span>

<span class="ansi-green-fg">============================== </span><span class="ansi-green-intense-fg ansi-bold">1 passed</span><span class="ansi-green-fg"> in 0.96s</span><span class="ansi-green-fg"> ===============================</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Create-test-data-in-fixtures">
<a class="anchor" href="#Create-test-data-in-fixtures" aria-hidden="true"><span class="octicon octicon-link"></span></a>Create test data in fixtures<a class="anchor-link" href="#Create-test-data-in-fixtures"> </a>
</h3>
<p>Right now we create the test data in the test. An alternative is to create the dataframe in a fixture. The advantage is that there is less code to read in the test, and the fixture can be reused by different tests, if we have several functions acting on the data we can avoid duplication of code. We create fixtures by using the decorator <code>@pytest.fixture</code>:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">pandas.testing</span> <span class="kn">import</span> <span class="n">assert_frame_equal</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">pytest</span>


<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">test_dataframe</span><span class="p">():</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"a"</span><span class="p">,</span> <span class="s2">"b"</span><span class="p">,</span> <span class="s2">"c"</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">df</span>


<span class="k">def</span> <span class="nf">test_save_fixturized</span><span class="p">(</span><span class="n">tmp_path</span><span class="p">,</span> <span class="n">test_dataframe</span><span class="p">):</span>
    <span class="c1"># Given</span>
    <span class="n">save_path</span> <span class="o">=</span> <span class="n">tmp_path</span> <span class="o">/</span> <span class="s2">"df.csv"</span>
    <span class="n">save</span><span class="p">(</span><span class="n">test_dataframe</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>

    <span class="c1"># When </span>
    <span class="n">df_actual</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Then </span>
    <span class="n">assert_frame_equal</span><span class="p">(</span><span class="n">test_dataframe</span><span class="p">,</span> <span class="n">df_actual</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python -m pytest test_save_example.py::test_save_fixturized
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-bold">============================= test session starts ==============================</span>
platform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1
rootdir: /Users/Gunnhild/code/notes/_notebooks, inifile: pytest.ini
collected 1 item                                                               <span class="ansi-bold">

test_save_example.py </span><span class="ansi-green-intense-fg ansi-bold">.</span><span class="ansi-green-fg">                                                   [100%]</span>

<span class="ansi-green-fg">============================== </span><span class="ansi-green-intense-fg ansi-bold">1 passed</span><span class="ansi-green-fg"> in 0.84s</span><span class="ansi-green-fg"> ===============================</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note that when we call the fixture function, we automatically get the return value, instead of the function itself, i.e. we do not need to use assign the return value of the function to a variable holding the dataframe: <code>df_expected = test_dataframe()</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Use-monkeypatch-to-set-environment-variables">
<a class="anchor" href="#Use-monkeypatch-to-set-environment-variables" aria-hidden="true"><span class="octicon octicon-link"></span></a>Use monkeypatch to set environment variables<a class="anchor-link" href="#Use-monkeypatch-to-set-environment-variables"> </a>
</h3>
<p>We often use environment variables to configure our functionality, such as where they should output their results, login credentials for databases and services. Keeping these configs in environment variables is <a href="https://12factor.net/config">recommended</a> in order to run the same code with different configurations in different environments: locally when developing, in a test environment and in a production environment. To test these functions, we can use <a href="https://docs.pytest.org/en/latest/monkeypatch.html">monkeypatching</a>. Let's say we read environment variables in our function:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>


<span class="k">def</span> <span class="nf">read_config</span><span class="p">():</span>
    <span class="n">password</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"DB_PASSWORD"</span><span class="p">]</span>
    <span class="n">user</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"DB_USER"</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">"password"</span><span class="p">:</span> <span class="n">password</span><span class="p">,</span> 
        <span class="s2">"user"</span><span class="p">:</span> <span class="n">user</span><span class="p">,</span>
    <span class="p">}</span>
</pre></div>
<p>We can then use the monkeypatch fixture in our test, to set environment variables to toy values for the test execution:</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_read_config</span><span class="p">(</span><span class="n">monkeypatch</span><span class="p">):</span>
    <span class="n">monkeypatch</span><span class="o">.</span><span class="n">setenv</span><span class="p">(</span><span class="s2">"DB_PASSWORD"</span><span class="p">,</span> <span class="s2">"password123"</span><span class="p">)</span>
    <span class="n">monkeypatch</span><span class="o">.</span><span class="n">setenv</span><span class="p">(</span><span class="s2">"DB_USER"</span><span class="p">,</span> <span class="s2">"username"</span><span class="p">)</span>
    <span class="n">conf</span> <span class="o">=</span> <span class="n">read_config</span><span class="p">()</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">conf</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">==</span> <span class="p">{</span><span class="s2">"password"</span><span class="p">,</span> <span class="s2">"user"</span><span class="p">}</span>
    <span class="k">assert</span> <span class="n">conf</span><span class="p">[</span><span class="s2">"password"</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"password123"</span>
    <span class="k">assert</span> <span class="n">conf</span><span class="p">[</span><span class="s2">"user"</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"username"</span>
</pre></div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python -m pytest test_monkeypatching.py::test_read_config
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-bold">============================= test session starts ==============================</span>
platform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1
rootdir: /Users/Gunnhild/code/notes/_notebooks, inifile: pytest.ini
collected 1 item                                                               

test_monkeypatching.py <span class="ansi-green-fg">.</span><span class="ansi-green-fg">                                                 [100%]</span>

<span class="ansi-green-fg">============================== </span><span class="ansi-green-intense-fg ansi-bold">1 passed</span><span class="ansi-green-fg"> in 0.02s</span><span class="ansi-green-fg"> ===============================</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We could extract the mocking into fixtures to share the setup between tests:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pytest</span>


<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">monkeypatch_config</span><span class="p">(</span><span class="n">monkeypatch</span><span class="p">):</span>
    <span class="n">monkeypatch</span><span class="o">.</span><span class="n">setenv</span><span class="p">(</span><span class="s2">"DB_PASSWORD"</span><span class="p">,</span> <span class="s2">"password123"</span><span class="p">)</span>
    <span class="n">monkeypatch</span><span class="o">.</span><span class="n">setenv</span><span class="p">(</span><span class="s2">"DB_USER"</span><span class="p">,</span> <span class="s2">"username"</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">test_read_config_using_fixture</span><span class="p">(</span><span class="n">monkeypatch_config</span><span class="p">):</span>
    <span class="n">conf</span> <span class="o">=</span> <span class="n">read_config</span><span class="p">()</span>
    <span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">conf</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">==</span> <span class="p">{</span><span class="s2">"password"</span><span class="p">,</span> <span class="s2">"user"</span><span class="p">}</span>
    <span class="k">assert</span> <span class="n">conf</span><span class="p">[</span><span class="s2">"password"</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"password123"</span>
    <span class="k">assert</span> <span class="n">conf</span><span class="p">[</span><span class="s2">"user"</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"username"</span>
</pre></div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python -m pytest test_monkeypatching.py::test_read_config_using_fixture
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-bold">============================= test session starts ==============================</span>
platform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1
rootdir: /Users/Gunnhild/code/notes/_notebooks, inifile: pytest.ini
collected 1 item                                                               

test_monkeypatching.py <span class="ansi-green-fg">.</span><span class="ansi-green-fg">                                                 [100%]</span>

<span class="ansi-green-fg">============================== </span><span class="ansi-green-intense-fg ansi-bold">1 passed</span><span class="ansi-green-fg"> in 0.02s</span><span class="ansi-green-fg"> ===============================</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Use-mocks-to-test-external-dependencies">
<a class="anchor" href="#Use-mocks-to-test-external-dependencies" aria-hidden="true"><span class="octicon octicon-link"></span></a>Use mocks to test external dependencies<a class="anchor-link" href="#Use-mocks-to-test-external-dependencies"> </a>
</h2>
<p>When we have external dependencies, such as an API or databases, we want our tests to be independent of the status of our dependencies. For instance, we want to test that our code can handle both when the API is up and running normally, and when the API is down. However, we can't control whether the API is up or down when we run our tests, so we use <em>mocks</em> to imitate the responses from our dependencies.</p>
<p>Mocking is a field big enough for it's own post at some point, but what I keep coming back to is a RealPython article on <a href="https://realpython.com/python-mock-library/">Understanding the Python Mock Object Library</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Use-parametrization-to-cover-multiple-cases">
<a class="anchor" href="#Use-parametrization-to-cover-multiple-cases" aria-hidden="true"><span class="octicon octicon-link"></span></a>Use parametrization to cover multiple cases<a class="anchor-link" href="#Use-parametrization-to-cover-multiple-cases"> </a>
</h2>
<p>There are at least two ways of rerunning tests for different test cases in order to ensure all execution paths are tested, and both involve parametrizing:</p>
<ul>
<li><a href="https://docs.pytest.org/en/latest/fixture.html#fixture-parametrize">Parametrizing fixtures</a></li>
<li><a href="https://docs.pytest.org/en/latest/parametrize.html#pytest-mark-parametrize-parametrizing-test-functions">Parametrizing tests</a></li>
</ul>
<p>When we parametrize, pytest will run the tests for all different cases we specify automatically.</p>
<p>In my experience, we should parametrize tests to ensure that we cover all the different cases that arise from having different input data to the function under test, i.e. the function specific stuff, whereas we should parametrize fixtures when we want to test different objects. If the fixtures are mocking external dependencies or our own complex objects, it may be a good idea to parameterize fixtures to ensure we cover different setups.</p>
<p>A code smell indicating that we should parametrize a fixture, is duplicated code for creating different tests for different functions, or setting up different test cases in the same test, across multiple tests. A nice side effect of parametrizing your fixtures, is that all new tests that use the same fixture will automatically be run for the different cases.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Parametrizing-fixtures-to-cover-multiple-test-cases">
<a class="anchor" href="#Parametrizing-fixtures-to-cover-multiple-test-cases" aria-hidden="true"><span class="octicon octicon-link"></span></a>Parametrizing fixtures to cover multiple test cases<a class="anchor-link" href="#Parametrizing-fixtures-to-cover-multiple-test-cases"> </a>
</h3>
<p>Let's go back to the <code>save</code> test example of saving a dataframe. 
</p>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg>
    <strong>Note: </strong>In this test, I have parametrized an input parameter to the function, but above I argued that input arguments is better suited for test parametrization than fixture parametrization. A better example would perhaps be if the data in the test was an attribute of a class, and we wished to create a mock of the class to test. It may also be suitable to extract input parameters to fixtures when creation is complex. In any case, the example serves to show some of the functionality of fixtures that we can use. 
</div>
<p>Where we left off, our test only covered one execution path: the first branch of the if statement, i.e. if the input dataframe is non-empty. If we want to test the other branch, we can parametrize the fixture to return different dataframes. When a test relies on a parametrized fixture, it will be rerun for all parametrizations of the fixture.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">pandas.testing</span> <span class="kn">import</span> <span class="n">assert_frame_equal</span>
<span class="kn">import</span> <span class="nn">pytest</span> 

<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span> <span class="n">ids</span><span class="o">=</span><span class="p">[</span><span class="s2">"non-empty"</span><span class="p">,</span> <span class="s2">"empty"</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">dataframes</span><span class="p">(</span><span class="n">request</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">request</span><span class="o">.</span><span class="n">param</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"a"</span><span class="p">,</span> <span class="s2">"b"</span><span class="p">,</span> <span class="s2">"c"</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">test_save_parametrized_fixture</span><span class="p">(</span><span class="n">tmp_path</span><span class="p">,</span> <span class="n">dataframes</span><span class="p">):</span>
    <span class="c1"># Given</span>
    <span class="n">save_path</span> <span class="o">=</span> <span class="n">tmp_path</span> <span class="o">/</span> <span class="s2">"df.csv"</span>
    <span class="n">save</span><span class="p">(</span><span class="n">dataframes</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dataframes</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
        <span class="c1"># When </span>
        <span class="n">files_in_dir</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tmp_path</span><span class="o">.</span><span class="n">iterdir</span><span class="p">()</span> <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">is_file</span><span class="p">()]</span>
        <span class="c1"># Then</span>
        <span class="k">assert</span> <span class="ow">not</span> <span class="n">files_in_dir</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># When</span>
        <span class="n">df_actual</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># Then </span>
        <span class="n">assert_frame_equal</span><span class="p">(</span><span class="n">dataframes</span><span class="p">,</span> <span class="n">df_actual</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python -m pytest test_save_example.py::test_save_parametrized_fixture
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-bold">============================= test session starts ==============================</span>
platform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1
rootdir: /Users/Gunnhild/code/notes/_notebooks, inifile: pytest.ini
collected 2 items                                                              <span class="ansi-bold">

test_save_example.py </span><span class="ansi-green-intense-fg ansi-bold">.</span><span class="ansi-green-fg">.</span><span class="ansi-green-fg">                                                  [100%]</span>

<span class="ansi-green-fg">============================== </span><span class="ansi-green-intense-fg ansi-bold">2 passed</span><span class="ansi-green-fg"> in 0.60s</span><span class="ansi-green-fg"> ===============================</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This executes the test twice automatically. We use the <code>params</code> keyword to parametrize our fixture, and the <code>ids</code> keyword to provide human readable names for our different parametrizations. We use the <code>request</code> fixture in our fixture to access the parameters we send in on the <code>request</code>'s attribute <code>param</code>.</p>
<p><code>params</code> takes a list as inputs, so if we need several arguments to our fixture function, we can use for example a list of tuples or a list of dicts:</p>
<div class="highlight"><pre><span></span><span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="p">[(</span><span class="kc">True</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="p">)],</span> <span class="n">ids</span><span class="o">=</span><span class="p">[</span><span class="s2">"non-empty"</span><span class="p">,</span> <span class="s2">"empty"</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">df_fixture_with_tuples</span><span class="p">(</span><span class="n">request</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">request</span><span class="o">.</span><span class="n">param</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">param</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"a"</span><span class="p">,</span> <span class="s2">"b"</span><span class="p">,</span> <span class="s2">"c"</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">n</span><span class="p">,</span><span class="mi">3</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>


<span class="nd">@pytest</span><span class="o">.</span><span class="n">fixture</span><span class="p">(</span>
    <span class="n">params</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s2">"non_empty"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">"length"</span><span class="p">:</span> <span class="mi">5</span><span class="p">},</span> 
        <span class="p">{</span><span class="s2">"non_empty"</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">"length"</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>
    <span class="p">],</span> 
    <span class="n">ids</span><span class="o">=</span><span class="p">[</span><span class="s2">"non-empty"</span><span class="p">,</span> <span class="s2">"empty"</span><span class="p">]</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">df_fixture_with_dict</span><span class="p">(</span><span class="n">request</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">request</span><span class="o">.</span><span class="n">param</span><span class="p">[</span><span class="s2">"non_empty"</span><span class="p">]:</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">param</span><span class="p">[</span><span class="s2">"length"</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"a"</span><span class="p">,</span> <span class="s2">"b"</span><span class="p">,</span> <span class="s2">"c"</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">n</span><span class="p">,</span><span class="mi">3</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lets run a failing test, to see our <code>id</code> in action, with this toy test function</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_demo_fail_output</span><span class="p">(</span><span class="n">dataframes</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">dataframes</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span>
        <span class="k">assert</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span> 
        <span class="k">assert</span> <span class="kc">True</span>
</pre></div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python -m pytest --tb<span class="o">=</span>line test_save_example.py::test_demo_fail_output
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-bold">============================= test session starts ==============================</span>
platform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1
rootdir: /Users/Gunnhild/code/notes/_notebooks, inifile: pytest.ini
collected 2 items                                                              <span class="ansi-bold">

test_save_example.py </span><span class="ansi-green-intense-fg ansi-bold">.</span><span class="ansi-red-fg">F</span><span class="ansi-red-fg">                                                  [100%]</span>

=================================== FAILURES ===================================
/Users/Gunnhild/code/notes/_notebooks/test_save_example.py:74: assert False
=========================== short test summary info ============================
FAILED test_save_example.py::test_demo_fail_output[empty] - assert False
<span class="ansi-red-fg">========================= </span><span class="ansi-red-intense-fg ansi-bold">1 failed</span>, <span class="ansi-green-fg">1 passed</span><span class="ansi-red-fg"> in 0.76s</span><span class="ansi-red-fg"> ==========================</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <code>id</code> of the failing test, <code>empty</code>, is printed in the list of failed tests. If you use PyCharm, you will find that  it prints a pretty summary of the ids of parametrized tests, both parametrized through fixtures and the test itself, by building up a tree of the tests that are run, organised by module, script, and function, and I'm sure many other IDEs have similar functionality.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Parametrize-tests-to-cover-multiple-test-cases">
<a class="anchor" href="#Parametrize-tests-to-cover-multiple-test-cases" aria-hidden="true"><span class="octicon octicon-link"></span></a>Parametrize tests to cover multiple test cases<a class="anchor-link" href="#Parametrize-tests-to-cover-multiple-test-cases"> </a>
</h3>
<p>To cover the different execution paths, we can also parametrize the test itself, which looks a little different. Let's return to our save example, but add to the functionality. Let's say we want to pass an argument for the number of rows to save, and add a validator to check that the number of rows is a valid argument:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>


<span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">save_path</span><span class="p">:</span> <span class="n">Path</span><span class="p">,</span> <span class="n">num_rows</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">df</span><span class="o">.</span><span class="n">empty</span><span class="p">:</span> 
        <span class="k">if</span> <span class="n">num_rows</span><span class="p">:</span> 
            <span class="n">num_rows</span> <span class="o">=</span> <span class="n">validate_num_rows</span><span class="p">(</span><span class="n">num_rows</span><span class="p">)</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span> <span class="n">num_rows</span><span class="p">]</span>
        <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Nothing to save. "</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">validate_num_rows</span><span class="p">(</span><span class="n">num_rows</span><span class="p">)</span><span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_rows</span><span class="p">)</span> <span class="o">==</span> <span class="n">num_rows</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"num_rows must be int, got </span><span class="si">{</span><span class="n">num_rows</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">num_rows</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"num_rows must be &gt;= 1, got </span><span class="si">{</span><span class="n">num_rows</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_rows</span><span class="p">)</span>
</pre></div>
<p>We parametrize our test to cover both the case when a <code>num_rows</code> argument is not supplied, and when it is supplied:</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">pytest</span> 


<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="n">argnames</span><span class="o">=</span><span class="s2">"number_of_rows"</span><span class="p">,</span> <span class="n">argvalues</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">test_save_fixturized</span><span class="p">(</span><span class="n">tmp_path</span><span class="p">,</span> <span class="n">test_dataframe</span><span class="p">,</span> <span class="n">number_of_rows</span><span class="p">):</span>
    <span class="n">save_path</span> <span class="o">=</span> <span class="n">tmp_path</span> <span class="o">/</span> <span class="s2">"df.csv"</span>
    <span class="n">save</span><span class="p">(</span><span class="n">test_dataframe</span><span class="p">,</span> <span class="n">save_path</span><span class="p">,</span> <span class="n">num_rows</span><span class="o">=</span><span class="n">number_of_rows</span><span class="p">)</span>

    <span class="n">df_actual</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">number_of_rows</span><span class="p">:</span>
        <span class="n">df_expected</span> <span class="o">=</span> <span class="n">test_dataframe</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">number_of_rows</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span> 
        <span class="n">df_expected</span> <span class="o">=</span> <span class="n">test_dataframe</span>

    <span class="n">assert_frame_equal</span><span class="p">(</span><span class="n">df_expected</span><span class="p">,</span> <span class="n">df_actual</span><span class="p">)</span>
</pre></div>
<p>Parametrize is a mark, where the first argument, <code>argnames</code>, is a string with the argument names separated by commas, the second, <code>argvalues</code> is a list with the argument values for the different test cases. If we have several arguments, <code>argvalues</code> must be a list of tuples, and the number of tuples must match the number of <code>argnames</code> for each element of the list. We use the parameterized values in the test by setting them as input arguments to the test. These names must match <code>argnames</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python -m pytest test_parametrize.py::test_save_fixturized
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-bold">============================= test session starts ==============================</span>
platform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1
rootdir: /Users/Gunnhild/code/notes/_notebooks, inifile: pytest.ini
collected 2 items                                                              <span class="ansi-bold">

test_parametrize.py </span><span class="ansi-green-intense-fg ansi-bold">.</span><span class="ansi-green-fg">.</span><span class="ansi-green-fg">                                                   [100%]</span>

<span class="ansi-green-fg">============================== </span><span class="ansi-green-intense-fg ansi-bold">2 passed</span><span class="ansi-green-fg"> in 0.79s</span><span class="ansi-green-fg"> ===============================</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Testing-that-exceptions-are-raised">
<a class="anchor" href="#Testing-that-exceptions-are-raised" aria-hidden="true"><span class="octicon octicon-link"></span></a>Testing that exceptions are raised<a class="anchor-link" href="#Testing-that-exceptions-are-raised"> </a>
</h2>
<p>To make assertions about expected exceptions, we use <code>pytest.raises</code>. We will use the function <code>validate_num_rows</code> as an example, as it raises errors in some cases, and not in others. This is also a good opportunity to document some assumptions for our future self about what this test does. Since there are many different cases, we will parametrize the test function to cover all branches of the code and demonstrate functionality.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pytest</span>


<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span>
    <span class="s2">"input_num_rows, expected_output, expected_error"</span><span class="p">,</span> 
    <span class="p">[</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="p">(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"text"</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">"3.4"</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">),</span>
        <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">),</span>
    <span class="p">],</span> 
    <span class="n">ids</span><span class="o">=</span><span class="p">[</span>
        <span class="s2">"integer"</span><span class="p">,</span>
        <span class="s2">"float_that_can_be_converted_to_integer"</span><span class="p">,</span>
        <span class="s2">"string_fails"</span><span class="p">,</span>
        <span class="s2">"float_fails"</span><span class="p">,</span>
        <span class="s2">"negative_number_fails"</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">test_validate_num_rows</span><span class="p">(</span><span class="n">input_num_rows</span><span class="p">,</span> <span class="n">expected_output</span><span class="p">,</span> <span class="n">expected_error</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">expected_error</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">pytest</span><span class="o">.</span><span class="n">raises</span><span class="p">(</span><span class="n">expected_error</span><span class="p">):</span>
            <span class="n">validate_num_rows</span><span class="p">(</span><span class="n">input_num_rows</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">actual_output</span> <span class="o">=</span> <span class="n">validate_num_rows</span><span class="p">(</span><span class="n">input_num_rows</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">expected_output</span> <span class="o">==</span> <span class="n">actual_output</span>
</pre></div>
<p>Now we have an example of having multiple argument names and argument values with tuples, as mentioned above.</p>
<p>To test for failure and success, we use the argument <code>expected_error</code> which we set to <code>None</code> for the test cases that should fail and to the error we expect when a test should pass. Then we use <code>pytest.raises</code> to call a function and validate that the expected error was thrown if <code>expected_error</code> is not <code>None</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python -m pytest test_parametrize.py::test_validate_num_rows
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-bold">============================= test session starts ==============================</span>
platform darwin -- Python 3.8.1, pytest-5.4.1, py-1.8.1, pluggy-0.13.1
rootdir: /Users/Gunnhild/code/notes/_notebooks, inifile: pytest.ini
collected 5 items                                                              <span class="ansi-bold">

test_parametrize.py </span><span class="ansi-green-intense-fg ansi-bold">.</span><span class="ansi-green-fg">.</span><span class="ansi-green-fg">.</span><span class="ansi-green-fg">.</span><span class="ansi-green-fg">.</span><span class="ansi-green-fg">                                                [100%]</span>

<span class="ansi-green-fg">============================== </span><span class="ansi-green-intense-fg ansi-bold">5 passed</span><span class="ansi-green-fg"> in 0.56s</span><span class="ansi-green-fg"> ===============================</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Another option for conditional raising of exeptions is shown <a href="https://docs.pytest.org/en/latest/example/parametrize.html#parametrizing-conditional-raising">in the documentation</a>, and uses a contextmanager that yields for non-failing cases. It seems a little complicated to me, but if you're used to this construction you can save some lines of code in your tests.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Further-reading">
<a class="anchor" href="#Further-reading" aria-hidden="true"><span class="octicon octicon-link"></span></a>Further reading<a class="anchor-link" href="#Further-reading"> </a>
</h2>
<p><em>Mocking</em> is an obvious next step when writing tests, my favorite source is the above mentioned RealPython article on <a href="https://realpython.com/python-mock-library/">Understanding the Python Mock Object Library</a>.</p>
<p><em>Code coverage</em> is a concept that goes hand in hand with testing and is a good starting point for what to test. <code>pytest-cov</code> is an easy coverage plugin for pytest.</p>
<p>The ecosystem of plugins to pytest is huge, and there are many I would like to try, for example<code>pytest-mock</code> for mocking and <code>pytest-vcr</code> for HTTP requests. <a href="https://joshpeak.net/posts/2019-06-18-Advanced-python-testing.html">This tutorial</a> covers both the <code>pytest-vcr</code> library, but also basic concepts in testing and code quality, as well as the author's strategy on how to read up on testing in Python.</p>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/notes/python/pytest/testing/2020/04/12/pytest.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/notes/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/notes/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/notes/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Learning by writing things down</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/gunnhildsp" title="gunnhildsp"><svg class="svg-icon grey"><use xlink:href="/notes/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/gunnhildsp" title="gunnhildsp"><svg class="svg-icon grey"><use xlink:href="/notes/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
